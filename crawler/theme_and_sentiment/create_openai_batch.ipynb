{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4257870f-a8db-41f7-a493-a44f5b1fe23e",
   "metadata": {},
   "source": [
    "# Creating songs theme and sentiment with chatgpt batch of jsol files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3455178-0045-48dd-aae2-939c0b823c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import openai\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append(parent_dir)\n",
    "sys.path.append('/home/or/dev/latin_music_statistics/crawler/data_dir')\n",
    "sys.path.append(os.path.abspath(os.path.join(parent_dir, 'statistics_dir')))\n",
    "\n",
    "from config import OPENAI_MODEL, THEME_PROMPT, SENTIMENT_PROMPT, BATCH_THEME_JSOL_FILE, BATCH_SENTIMENT_JSOL_FILE, DATA_JSOL_DIR, FINAL_DATA_FILE\n",
    "df = pd.read_csv('/home/or/dev/latin_music_statistics/crawler/data_dir/processed_data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0d0c5d82-8a9c-40ed-a871-f3e9b13cc46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_JSOL_DIR = os.path.join(DATA_DIR, 'jsol')\n",
    "\n",
    "# BATCH_THEME_JSOL_FILE = os.path.join(DATA_JSOL_DIR, 'batch_song_theme')\n",
    "# BATCH_SENTIMENT_JSOL_FILE = os.path.join(DATA_JSOL_DIR, 'batch_song_sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "228eb335-cbb2-4a93-9da9-34b04bfc5824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creare_jsol_batch_file(base_file_name, openai_model, prompt, batch_size):\n",
    "    num_batches = int(np.ceil(len(df) / batch_size))\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        batch_df = df.iloc[i * batch_size:(i + 1) * batch_size]\n",
    "        batch_file_name = f'{base_file_name}_{i + 1}.jsonl'\n",
    "        \n",
    "        with open(batch_file_name, 'w') as outfile:\n",
    "            for ii, (idx, row) in enumerate(batch_df.iterrows()):\n",
    "                openai_row = {\n",
    "                    \"custom_id\": f\"request-{ii + i * batch_size}\",\n",
    "                    \"method\": \"POST\",\n",
    "                    \"url\": \"/v1/chat/completions\",\n",
    "                    \"body\": {\n",
    "                        \"model\": openai_model,\n",
    "                        \"messages\": [\n",
    "                            {\n",
    "                                \"role\": \"user\",\n",
    "                                \"content\": prompt.format(song=row['clean_lyrics'])\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "                outfile.write(json.dumps(openai_row) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "da67e64b-7676-47ec-9f4b-ec4834552e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "creare_jsol_batch_file(BATCH_THEME_JSOL_FILE, OPENAI_MODEL, THEME_PROMPT, OPENAI_BATCH_SIZE)\n",
    "creare_jsol_batch_file(BATCH_SENTIMENT_JSOL_FILE, OPENAI_MODEL, SENTIMENT_PROMPT, OPENAI_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4aeef009-12c5-4ff5-bdca-c39973bca490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Theme\n",
    "\n",
    "# creare_jsol_batch_file(batch_file_name, openai_model, prompt):\n",
    "\n",
    "# with open(BATCH_THEME_JSOL_FILE, 'w') as outfile:\n",
    "#     for ii, (idx, row) in enumerate(df.iterrows()):\n",
    "#         # Create the JSON object\n",
    "#         openai_row = {\n",
    "#             \"custom_id\": f\"request-{ii}\",\n",
    "#             \"method\": \"POST\",\n",
    "#             \"url\": \"/v1/chat/completions\",\n",
    "#             \"body\": {\n",
    "#                 \"model\": OPENAI_MODEL,\n",
    "#                 \"messages\": [\n",
    "#                     {\n",
    "#                         \"role\": \"user\",\n",
    "#                         \"content\": THEME_PROMPT + row['clean_lyrics']\n",
    "#                     }\n",
    "#                 ]\n",
    "#             }\n",
    "#         }\n",
    "        \n",
    "#         outfile.write(json.dumps(openai_row) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "096ff1f8-cc97-4e7e-9324-7ad441cf9b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sentiment\n",
    "\n",
    "# with open(BATCH_SENTIMENT_JSOL_FILE, 'w') as outfile:\n",
    "#     for ii, (idx, row) in enumerate(df.iterrows()):\n",
    "#         # Create the JSON object\n",
    "#         openai_row = {\n",
    "#             \"custom_id\": f\"request-{ii}\",\n",
    "#             \"method\": \"POST\",\n",
    "#             \"url\": \"/v1/chat/completions\",\n",
    "#             \"body\": {\n",
    "#                 \"model\": OPENAI_MODEL,\n",
    "#                 \"messages\": [\n",
    "#                     {\n",
    "#                         \"role\": \"user\",\n",
    "#                         \"content\": SENTIMENT_PROMPT.format(song=row['clean_lyrics'])\n",
    "#                     }\n",
    "#                 ]\n",
    "#             }\n",
    "#         }\n",
    "        \n",
    "\n",
    "#         outfile.write(json.dumps(openai_row) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7ba8ec55-79c9-4c5f-a157-3dabd60a18fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch(batches_dir):\n",
    "    batch_list = []\n",
    "    \n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(batches_dir):\n",
    "        if filename.endswith(\".jsonl\"):\n",
    "            # Full path to the file\n",
    "            file_path = os.path.join(batches_dir, filename)\n",
    "            \n",
    "            # Upload the file and append the result to the list\n",
    "            batch_file_status = client.files.create(file=open(file_path, \"rb\"), purpose=\"batch\")\n",
    "\n",
    "            batch_list.append(batch_file_status)\n",
    "\n",
    "    return batch_list\n",
    "\n",
    "load_batch_list = create_batch(DATA_JSOL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb48fc3-2917-44ae-a40e-0b613477f7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def run_batch(batch_list):\n",
    "    batch_run_status_list = []\n",
    "\n",
    "    for single_batch in batch_list:\n",
    "        batch_status = client.batches.create(\n",
    "            input_file_id=single_batch.id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\",\n",
    "            metadata={\n",
    "              \"description\": \"nightly eval job\"\n",
    "            }\n",
    "        )\n",
    "    \n",
    "        batch_run_status_list.append(batch_status)\n",
    "        time.sleep(1)\n",
    "\n",
    "    return batch_run_status_list\n",
    "\n",
    "batch_run_status_list = run_batch(batch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "9c9533ee-2a47-41d4-ba17-074566d89f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1686\n"
     ]
    }
   ],
   "source": [
    "# iF the previous failed - then run this to get how man ran successfully\n",
    "matching_files = []\n",
    "seen_filenames = set()  # A set to track filenames that have already been added\n",
    "batches_retrieve_list = client.batches.list()\n",
    "\n",
    "# Loop through the batches_list\n",
    "for batch in batches_retrieve_list:\n",
    "    # Check if the batch status is 'completed'\n",
    "    if batch.status == 'completed':\n",
    "        # Get the input_file_id from the batch\n",
    "        input_file_id = batch.input_file_id\n",
    "        \n",
    "        # Loop through the batch_list to find the matching file\n",
    "        for file_obj in load_batch_list:\n",
    "            if file_obj.id == input_file_id:\n",
    "                # Check if the filename has already been added to matching_files\n",
    "                if file_obj.filename not in seen_filenames:\n",
    "                    # Record the matching input_file_id, filename, and output_file_id\n",
    "                    matching_files.append({\n",
    "                        'input_file_id': input_file_id,\n",
    "                        'filename': file_obj.filename,\n",
    "                        'output_file_id': batch.output_file_id\n",
    "                    })\n",
    "                    # Add the filename to the seen set\n",
    "                    seen_filenames.add(file_obj.filename)\n",
    "\n",
    "print(len(matching_files))\n",
    "\n",
    "# # matching_files now contains all the matched files with 'completed' status without duplicates\n",
    "# for match in matching_files:\n",
    "#     print(f\"input_file_id: {match['input_file_id']}, filename: {match['filename']}, output_file_id: {match['output_file_id']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f7535826-18fe-4125-b775-8a051f529f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rerun only failed batches running  - run the all faile/unran files\n",
    "# # Step 1: Extract the filenames from matching_files\n",
    "# processed_filenames = set([item['filename'] for item in matching_files])\n",
    "\n",
    "# # Step 2: Filter batch_list to include only files not in processed_filenames\n",
    "# filtered_batch_list = [file_obj for file_obj in load_batch_list if file_obj.filename not in processed_filenames]\n",
    "\n",
    "# # Step 3: Run the run_batch function with the filtered list\n",
    "# print(len(filtered_batch_list))\n",
    "# if filtered_batch_list:\n",
    "#     batch_run_status_list = run_batch(filtered_batch_list)\n",
    "#     # Now batch_run_status_list contains the statuses of the newly run batches\n",
    "# else:\n",
    "#     print(\"All files have already been processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "083fec54-92a8-45f4-b7a7-3a75700de611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('batch_list.pkl', 'wb') as outfile:\n",
    "#     pickle.dump(batch_list, outfile)\n",
    "\n",
    "# with open('batch_run_status_list.pkl', 'wb') as outfile:\n",
    "#     pickle.dump(batch_run_status_list, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "67bc2f4a-a7d5-4b50-bfc6-5ff29fabbf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Match raw the response\n",
    "# for record in matching_files:\n",
    "#     file_response = client.files.content(record['output_file_id'])\n",
    "#     raw_response = json.loads(file_response.text)['response']['body']['choices'][0]['message']['content']\n",
    "#     record['raw_response'] = raw_response\n",
    "\n",
    "# # Function to extract the numeric part from the filename\n",
    "# def extract_number(filename):\n",
    "#     match = re.search(r'(\\d+)\\.jsonl$', filename)\n",
    "#     return int(match.group(1)) if match else 0\n",
    "\n",
    "# # Sort the list based on the numeric part of the filename\n",
    "# matching_files_sorted = sorted(matching_files, key=lambda x: extract_number(x['filename']))\n",
    "\n",
    "# # Split into two lists based on the type in the filename\n",
    "# theme_records_list = [file for file in matching_files_sorted if 'theme' in file['filename']]\n",
    "# sentiment_records_list = [file for file in matching_files_sorted if 'sentiment' in file['filename']]\n",
    "\n",
    "# clean_theme_response_list = []\n",
    "# clean_sentiment_response_list_raw = []\n",
    "\n",
    "# for record in theme_records_list:\n",
    "#     clean_theme_response_list.append(record['raw_response'].replace(\"The song theme is:\", \"\").strip())\n",
    "\n",
    "# for record in sentiment_records_list:\n",
    "#     clean_sentiment_response_list_raw.append(eval(record['raw_response'].replace(\"json\", \"\").replace(\"```\",\"\").strip()))\n",
    "\n",
    "\n",
    "# # Function to normalize and extract sentiment values\n",
    "# def normalize_and_extract(entry):\n",
    "#     # Handle entries with 'sentiment' or 'sentiment_analysis' keys\n",
    "#     if 'sentiment' in entry:\n",
    "#         sentiment = entry['sentiment']\n",
    "#     elif 'sentiment_analysis' in entry:\n",
    "#         sentiment = entry['sentiment_analysis']\n",
    "#     elif 'overall_sentiment' in entry:\n",
    "#         sentiment = entry['overall_sentiment']\n",
    "#     else:\n",
    "#         sentiment = entry\n",
    "\n",
    "#     # Normalize values: divide by 100 if they are greater than 1\n",
    "#     normalized_sentiment = {key: value / 100 if value > 1 else value for key, value in sentiment.items()}\n",
    "    \n",
    "#     return normalized_sentiment\n",
    "\n",
    "# # Apply the normalization function to each dictionary in the list\n",
    "# clean_sentiment_response_list = [normalize_and_extract(entry) for entry in clean_sentiment_response_list_raw]\n",
    "\n",
    "# df['theme'] = clean_theme_response_list\n",
    "# df['sentiment'] = clean_sentiment_response_list\n",
    "\n",
    "# df.to_csv(FINAL_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee9ece2d-62f3-46c2-9580-bcb7649b0e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/or/dev/latin_music_statistics/crawler/data_dir/final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40aa8cb9-f8ad-4b6c-b52e-d9dee01a4ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0.3','Unnamed: 0.2','Unnamed: 0.1','Unnamed: 0'],axis=1,inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "13252744-3229-4975-87d6-8d5580f9faf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9fdd268d-4613-4bab-8a41-6c45ddbf48d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Songs without lyrics: 0\n",
      "Songs which Spanish was not detected: 95\n",
      "Songs which Spanish was detected and below the threshold=0.98: 35\n",
      "Songs which Spanish was detected and above the threshold=0.98: 861\n",
      "Percentage of the data selected: 0.87%\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from lyricsgenius import Genius\n",
    "from config import DATA_FILE, CHORUS_SAMPLE_NUMBER, SPANISH_THRESHOLD\n",
    "from helper import header_and_footer_removal, separate_chorus_rest, spanish_detection, text_cleaning, print_sample_chorus\n",
    "\n",
    "GENIUS_API_TOKEN = 'Od2yrHNfOCRHimIH3ev-wGZxZNJz3-47I4QfpzihKstD4eQaCItV28UJ72MAiV2W'\n",
    "\n",
    "genius = Genius(GENIUS_API_TOKEN, timeout=15, retries=3)\n",
    "\n",
    "df = pd.read_csv(DATA_FILE, encoding = 'utf-8')\n",
    "all_lyrics = df['lyrics'].to_list()\n",
    "\n",
    "\n",
    "selected_lyrics = []\n",
    "chorus_list = []\n",
    "song_wo_chorus_list = []\n",
    "all_chorus_list = []\n",
    "chorus_counter_list = []\n",
    "\n",
    "songs_with_only_header_footer = 0\n",
    "\n",
    "spanish_lyrics = spanish_detection(all_lyrics, SPANISH_THRESHOLD)\n",
    "\n",
    "for lyrics in spanish_lyrics:\n",
    "    lyrics_body = header_and_footer_removal(lyrics)\n",
    "    \n",
    "    if len(lyrics_body):\n",
    "        chorus, rest, all_chorus, chorus_counter = separate_chorus_rest(lyrics_body)\n",
    "    \n",
    "        selected_lyrics.append(lyrics_body)\n",
    "        chorus_list.append(chorus)\n",
    "        song_wo_chorus_list.append(rest)\n",
    "        all_chorus_list.append(all_chorus)\n",
    "        chorus_counter_list.append(chorus_counter)\n",
    "        \n",
    "    else:\n",
    "        songs_with_only_header_footer += 1\n",
    "\n",
    "if songs_with_only_header_footer:\n",
    "    print(f\"Number of songs with only header and footer : {songs_with_only_header_footer}\")\n",
    "    \n",
    "\n",
    "# print original and split chorus to files\n",
    "# print_sample_chorus(CHORUS_SAMPLE_NUMBER, clean_lyrics, chorus_counter_list,  all_chorus_list)\n",
    "# Analysis of 50 Song Choruses:\n",
    "# Identical Choruses: 38\n",
    "# Almost Identical Choruses: 5\n",
    "# Different Choruses: 7\n",
    "\n",
    "\n",
    "clean_selected_lyrics = text_cleaning(selected_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9522f8af-173b-4163-a222-7d3652f0766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "# import torch\n",
    "\n",
    "# # Load pre-trained model and tokenizer\n",
    "# model_name = 'gpt2'\n",
    "# model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# # Function to generate text\n",
    "# def generate_text(prompt, additional_response_length=20):\n",
    "#     # Encode the input prompt\n",
    "#     input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "#     max_length = input_ids.shape[1] + additional_response_length\n",
    "#     attention_mask = torch.ones(input_ids.shape, dtype=torch.long)\n",
    "\n",
    "#     # Generate text\n",
    "#     output = model.generate(\n",
    "#         input_ids,\n",
    "#         attention_mask=attention_mask,\n",
    "#         max_length=max_length,\n",
    "#         num_return_sequences=1,\n",
    "#         pad_token_id=tokenizer.eos_token_id\n",
    "#     )\n",
    "\n",
    "#     # Decode and return the generated text\n",
    "#     return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# # Example usage\n",
    "# prompt = \"write in one short sentence the topic of the song:\\n\" + clean_selected_lyrics[0] + \"\\nThe topic of the song is:\"\n",
    "# generated_text = generate_text(prompt)\n",
    "# print(generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00c6ff2-063f-4bbb-b286-e6ca697d279a",
   "metadata": {},
   "source": [
    "# Expirement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d739c3a0-c00c-4e16-886e-fff5d0830c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=NEG, probas={NEG: 0.569, NEU: 0.384, POS: 0.047})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# robertuito-sentiment-analysis\n",
    "from pysentimiento import create_analyzer\n",
    "analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
    "\n",
    "analyzer.predict(clean_selected_lyrics[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446df79d-fc62-4499-bced-2eb2bd87a9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "See Prince Royce LiveGet tickets as low as $45You might also like\n",
    "See Aventura LiveGet tickets as low as $40You might also like\n",
    "See Bad Bunny LiveGet tickets as low as $19You might also like\n",
    "See KHEA LiveGet tickets as low as $15You might also like\n",
    "You might also like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9d8b021a-7102-4335-aeb4-24270599c9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=NEG, probas={NEG: 0.808, NEU: 0.178, POS: 0.013})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.predict(\"\\nYa me han informado que tu novio es un insípido aburrido\\nTú que eres fogata y él tan frío\\nDice tu amiguita que es celoso no quiere que sea tu amigo\\nSospecha que soy un pirata y robaré su flor\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ac1ab79c-377f-4712-94c3-4ad23dc9d637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=NEG, probas={NEG: 0.675, NEU: 0.302, POS: 0.023})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.predict(\"\\nYa me han informado que tu novio es un insípido aburrido\\nTú que eres fogata y él tan frío\\nDice tu amiguita que es celoso no quiere que sea tu amigo\\nSospecha que soy un pirata y robaré su flor\\n\\nNo te asombres si una noche\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "683571f1-713c-4035-a10a-1130ff997a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=NEG, probas={NEG: 0.613, NEU: 0.355, POS: 0.033})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.predict(\"informado que tu novio es un insípido aburrido\\nTú que eres fogata y él tan frío\\nDice tu amiguita que es celoso no quiere que sea tu amigo\\nSospecha que soy un pirata y robaré su flor\\n\\nNo te asombres si una noche\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "83f59c7b-1ff1-4b9e-9e91-c9308cb834f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEG, NEU, POS = 0, 0, 0\n",
    "\n",
    "for item in aa:\n",
    "    neg_value, neu_value, pos_value = item.values()\n",
    "    NEG += neg_value\n",
    "    NEU += neu_value\n",
    "    POS += pos_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3ca88bfa-dc2f-414a-b487-b2656fb5336f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2eabd4fc-e421-425a-bd50-2e1a2de398f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22000983592627918 0.4274112074556997 0.3525789552052521\n"
     ]
    }
   ],
   "source": [
    "print(NEG/len(aa),NEU/len(aa),POS/len(aa))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

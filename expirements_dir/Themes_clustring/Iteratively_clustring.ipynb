{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b30ba0-289a-4435-b583-e747f0c8c469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to cluter 5% of the data iterativly moing cluster with samples below threshold into miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7607ae6-66b2-45a6-881a-c5f305989377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append(parent_dir)\n",
    "sys.path.append('/home/or/dev/latin_music_statistics/crawler/data_dir')\n",
    "sys.path.append(os.path.abspath(os.path.join(parent_dir, 'statistics_dir')))\n",
    "sys.path.append(os.path.abspath(os.path.join(parent_dir, 'theme_and_sentiment')))\n",
    "client = OpenAI(api_key = OPENAI_KEY)\n",
    "\n",
    "df = pd.read_csv('/home/or/dev/latin_music_statistics/crawler/data_dir/final_data.csv')\n",
    "df.drop(['general_theme'],axis=1,inplace=True)\n",
    "df[\"all_artists\"] = df[\"all_artists\"].apply(lambda x: eval(x))\n",
    "\n",
    "df_all_artist = df.explode(\"all_artists\")\n",
    "df_artist = df_all_artist[df_all_artist[\"all_artists\"] == 'Frank Reyes']\n",
    "df= df_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e0d01a-6f4b-4911-8620-a47e131a4c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering_general_theme import find_generic_theme, batch_process_themes, check_max_clusters\n",
    "from config import MAX_THEME_CLUSTER_SIZE, THEME_BATCH_SIZE, SONGS_CLUSTERING_PROMPT, CLUSTERS_PROMPT, OPENAI_MODEL, DATA_THEME_SINGERS_DIR, ROBERTA_EMBEDDINGS_MODEL\n",
    "\n",
    "def get_general_themes(songs_theme_list, client, logger, max_clusters=None):\n",
    "    if max_clusters is None:\n",
    "        max_clusters = MAX_THEME_CLUSTER_SIZE\n",
    "        \n",
    "    prev_text = ''\n",
    "    \n",
    "    clustered_themes, failed_extraction = batch_process_themes(songs_theme_list, prev_text, SONGS_CLUSTERING_PROMPT, THEME_BATCH_SIZE, OPENAI_MODEL, client, logger)\n",
    "    \n",
    "    len_clusters_before = len(clustered_themes)\n",
    "    continue_clustring = check_max_clusters(failed_extraction, max_clusters, len_clusters_before)\n",
    "    \n",
    "    decreasing_clusters_attempt = 1\n",
    "    logger.info(f\"Initial number of clusters: {len_clusters_before}\")\n",
    "    \n",
    "    while continue_clustring:\n",
    "        curr_clustered_themes, failed_extraction = batch_process_themes(clustered_themes, prev_text, CLUSTERS_PROMPT, THEME_BATCH_SIZE, OPENAI_MODEL, client, logger)\n",
    "        prev_clusters_text = '\\n'.join(clustered_themes)\n",
    "        curr_clusters_text = '\\n'.join(curr_clustered_themes)\n",
    "        len_clusters_after = len(curr_clustered_themes)\n",
    "        \n",
    "        logger.info(f\"The number of clusters: {len_clusters_after}\")\n",
    "    \n",
    "        if len_clusters_before == len_clusters_after:\n",
    "            decreasing_clusters_attempt += 1\n",
    "            prev_text =  f'This is the {decreasing_clusters_attempt} attempt for clustering. ' +\\\n",
    "                         f'There are {len_clusters_after} many clusters - which are too many. ' +\\\n",
    "                         f'The previous clustered topic attempt was:\\n{prev_clusters_text}\\n\\n\\nTry again with those topics:\\n' + curr_clusters_text\n",
    "        else:\n",
    "            decreasing_clusters_attempt = 1\n",
    "            prev_text = ''\n",
    "    \n",
    "        continue_clustring = check_max_clusters(failed_extraction, max_clusters, len_clusters_after)\n",
    "    \n",
    "        clustered_themes = curr_clustered_themes\n",
    "        len_clusters_before = len_clusters_after\n",
    "\n",
    "\n",
    "    logger.info(f\"The final number of clusters: {len(clustered_themes)}\")\n",
    "    return clustered_themes\n",
    "\n",
    "\n",
    "def match_generic_theme(df, df_general_themes, tgt_theme_col_name, client, untouched_cluster_name):\n",
    "    if tgt_theme_col_name not in df.columns:\n",
    "        df[tgt_theme_col_name] = \"\"\n",
    "        \n",
    "    general_themes = df_general_themes['general_theme'].tolist()\n",
    "    \n",
    "    # Use tqdm to add a progress bar to the loop\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
    "        if row[tgt_theme_col_name] != untouched_cluster_name:\n",
    "            result = find_generic_theme(row['theme'], general_themes, client)\n",
    "            df.at[index, tgt_theme_col_name] = result\n",
    "            \n",
    "\n",
    "OPENAI_KEY = \"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\"\n",
    "client = OpenAI(api_key = OPENAI_KEY)\n",
    "cluster_num = len(df) // 10 ############################# 20\n",
    "samples_in_cluster = int((len(df) // cluster_num) * 0.75)\n",
    "\n",
    "    \n",
    "# Establish logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler()          # Log messages to the console (stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "selected_df = df.copy()\n",
    "ration_of_total_samples = 1\n",
    "ration_of_small_clusters = 1\n",
    "THRESHOLD_CLUSTERS_RATIO = 0.4\n",
    "THRESHOLD_SAMPLES_RATIO = 0.8\n",
    "trail_num = 1\n",
    "MIS_CLISTER_NAME = 'Miscellaneous'\n",
    "below_threshold = {}\n",
    "\n",
    "# Sufficient low frequencies number of clusters and the total amount of samples are compartively large\n",
    "while THRESHOLD_CLUSTERS_RATIO < ration_of_small_clusters and THRESHOLD_SAMPLES_RATIO < ration_of_total_samples:\n",
    "\n",
    "    selected_df_indicies = []\n",
    "    for index, row in df.iterrows():\n",
    "        if 'general_theme' in df.columns and row['general_theme'] in below_threshold.keys():\n",
    "            df.at[index, 'general_theme'] = MIS_CLISTER_NAME\n",
    "        else:\n",
    "            selected_df_indicies.append(index)\n",
    "            \n",
    "    selected_df = df.loc[selected_df_indicies]\n",
    "    \n",
    "    # Find general themes\n",
    "    songs_theme_list = selected_df['theme'].tolist()\n",
    "\n",
    "    general_themes_list = get_general_themes(songs_theme_list, client, logger, max_clusters = cluster_num)\n",
    "    general_themes_df = pd.DataFrame(general_themes_list, columns = ['general_theme'])\n",
    "    print('-'*100)\n",
    "    print(general_themes_list)\n",
    "    print('-'*100)\n",
    "    match_generic_theme(df, general_themes_df, 'general_theme', client, MIS_CLISTER_NAME)\n",
    "\n",
    "    # check sufficient criteria for clusters    \n",
    "    general_theme_counts = df['general_theme'].value_counts().to_dict()\n",
    "    \n",
    "    if MIS_CLISTER_NAME in general_theme_counts:\n",
    "        del general_theme_counts[MIS_CLISTER_NAME]\n",
    "        \n",
    "        above_threshold = {key: value for key, value in general_theme_counts.items() if value >= samples_in_cluster}\n",
    "        below_threshold = {key: value for key, value in general_theme_counts.items() if value < samples_in_cluster}\n",
    "        ration_of_total_samples  = sum(general_theme_counts.values())/ len(df)\n",
    "    ration_of_small_clusters = len(below_threshold) / len(general_theme_counts)\n",
    "\n",
    "\n",
    "    logging.info(\n",
    "    f'Trail-({trail_num}): The themes and samples within them are:\\n{general_theme_counts}\\n'\n",
    "    f'Number(ratio) of total samples to recluster relative to the original dataset: {THRESHOLD_SAMPLES_RATIO}(threshols) < {ration_of_total_samples}\\n'\n",
    "    f'Number(ratio) of clusters below threshold of number of samples within: {ration_of_small_clusters} < {THRESHOLD_CLUSTERS_RATIO}(threshols)'\n",
    "    )\n",
    "    \n",
    "    trail_num +=1\n",
    "\n",
    "    if trail_num == 3:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
